#!/usr/bin/env bash
set -euo pipefail

rm -fr ~/.kube
mkdir -p ~/.kube
alias kubectl='microk8s kubectl'
alias helm='microk8s helm3'
sudo sysctl -w vm.max_map_count=262144
sudo sysctl -w fs.file-max=65536
sudo microk8s reset
sudo microk8s status --wait-ready
sudo microk8s enable dns
sudo microk8s enable hostpath-storage
sudo microk8s enable registry
sudo microk8s enable rbac
sudo microk8s enable helm3
sudo microk8s enable metrics-server
sudo microk8s enable metallb:192.168.1.129-192.168.1.254
microk8s config > ~/.kube/config

################################################################################

kubectl create namespace apps --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace auth --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace cert-manager --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace ci --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace data --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace docs --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace external-secrets-system --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace gateway --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace messaging --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace metallb-system --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace observability --dry-run=client -o yaml | kubectl apply -f -
kubectl create namespace temporal --dry-run=client -o yaml | kubectl apply -f -
kubectl label namespace apps name=apps --overwrite
kubectl label namespace auth name=auth --overwrite
kubectl label namespace ci name=ci --overwrite
kubectl label namespace data name=data --overwrite
kubectl label namespace docs name=docs --overwrite
kubectl label namespace gateway name=gateway --overwrite
kubectl label namespace messaging name=messaging --overwrite
kubectl label namespace observability name=observability --overwrite
kubectl label namespace temporal name=temporal --overwrite
kubectl label namespace apps pod-security.kubernetes.io/enforce=restricted --overwrite
kubectl label namespace auth pod-security.kubernetes.io/enforce=restricted --overwrite
kubectl label namespace ci pod-security.kubernetes.io/enforce=restricted --overwrite
kubectl label namespace data pod-security.kubernetes.io/enforce=restricted --overwrite
kubectl label namespace docs pod-security.kubernetes.io/enforce=restricted --overwrite
kubectl label namespace gateway pod-security.kubernetes.io/enforce=baseline --overwrite
kubectl label namespace messaging pod-security.kubernetes.io/enforce=restricted --overwrite

################################################################################

helm repo add akhq https://akhq.io
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add codecentric https://codecentric.github.io/helm-charts
helm repo add external-secrets https://charts.external-secrets.io
helm repo add gitlab https://charts.gitlab.io
helm repo add grafana https://grafana.github.io/helm-charts
helm repo add jetstack https://charts.jetstack.io
helm repo add kong https://charts.konghq.com
helm repo add nats https://nats-io.github.io/k8s/helm/charts
helm repo add netdata https://netdata.github.io/helmchart
helm repo add opensearch https://opensearch-project.github.io/helm-charts
helm repo add opentelemetry https://open-telemetry.github.io/opentelemetry-helm-charts
helm repo add ot-helm https://ot-container-kit.github.io/helm-charts
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add redisinsight https://raw.githubusercontent.com/hansehe/redisinsight-helm/master/helm/charts
helm repo add runix https://helm.runix.net
helm repo add sonarqube https://SonarSource.github.io/helm-chart-sonarqube
helm repo add strimzi https://strimzi.io/charts/
helm repo add temporal https://go.temporal.io/helm-charts
helm repo add vmware-tanzu https://vmware-tanzu.github.io/helm-charts
helm repo add icoretech https://icoretech.github.io/helm
helm repo update
kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.3.0/standard-install.yaml

################################################################################

helm upgrade --install cert-manager jetstack/cert-manager --namespace cert-manager --version 1.18.2 --set installCRDs=true
helm upgrade --install external-secrets external-secrets/external-secrets --namespace external-secrets-system --version 0.12.1
CA_BUNDLE=$(kubectl config view --raw --flatten -o jsonpath='{.clusters[0].cluster.certificate-authority-data}')
kubectl apply -f - <<EOF
apiVersion: external-secrets.io/v1beta1
kind: ClusterSecretStore
metadata:
  name: k8s-secrets-store
spec:
  provider:
    kubernetes:
      remoteNamespace: external-secrets-system
      server:
        url: https://kubernetes.default.svc
        caBundle: ${CA_BUNDLE}
      auth:
        serviceAccount:
          name: external-secrets-sa
          namespace: external-secrets-system
EOF
kubectl apply -f - <<EOF
apiVersion: v1
kind: ServiceAccount
metadata:
  name: external-secrets-sa
  namespace: external-secrets-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: external-secrets-reader
  namespace: external-secrets-system
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get","list","watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: external-secrets-reader-binding
  namespace: external-secrets-system
subjects:
- kind: ServiceAccount
  name: external-secrets-sa
  namespace: external-secrets-system
roleRef:
  kind: Role
  apiGroup: rbac.authorization.k8s.io
  name: external-secrets-reader
EOF
kubectl apply -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: cloudflare-api-token-source
  namespace: external-secrets-system
type: Opaque
stringData:
  token: He7sJey3TBY-LqP5kB5i7dGt-bTSVFElAjxNL_a5
EOF
kubectl apply -f - <<EOF
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: cloudflare-token
  namespace: cert-manager
spec:
  refreshInterval: 24h
  secretStoreRef:
    name: k8s-secrets-store
    kind: ClusterSecretStore
  target:
    name: cloudflare-api-token
    creationPolicy: Owner
  data:
  - secretKey: token
    remoteRef:
      key: cloudflare-api-token-source
      property: token
EOF
kubectl apply -f - <<EOF
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-dns
spec:
  acme:
    email: root@aldous.info
    server: https://acme-v02.api.letsencrypt.org/directory
    privateKeySecretRef:
      name: le-account-key
    solvers:
    - dns01:
        cloudflare:
          email: root@aldous.info
          apiTokenSecretRef:
            name: cloudflare-api-token
            key: token
EOF
kubectl apply -f - <<EOF
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: edge-cert
  namespace: gateway
spec:
  secretName: edge-cert
  issuerRef:
    name: letsencrypt-dns
    kind: ClusterIssuer
  dnsNames:
  - aldous.info
  - "*.aldous.info"
EOF

################################################################################

helm upgrade --install kong kong/kong --namespace gateway --version 2.51.0 --set ingressController.enabled=true --set ingressController.ingressClass=kong --set gateway.enabled=true --set proxy.type=LoadBalancer --set proxy.annotations.metallb\\.universe\\.tf/address-pool=lan-pool --set env.KONG_DATABASE=off
kubectl apply -f - <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: GatewayClass
metadata:
  name: kong
spec:
  controllerName: konghq.com/kic-gateway-controller
---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: edge
  namespace: gateway
spec:
  gatewayClassName: kong
  listeners:
  - name: https
    protocol: HTTPS
    port: 443
    tls:
      mode: Terminate
      certificateRefs:
      - kind: Secret
        name: edge-cert
    allowedRoutes:
      namespaces:
        from: All
EOF
helm upgrade --install postgresql bitnami/postgresql --namespace data --version 15.2.5 --set auth.postgresPassword=supersecret --set primary.persistence.size=50Gi --set primary.persistence.storageClass=microk8s-hostpath
helm upgrade --install pgbouncer icoretech/pgbouncer --namespace data --create-namespace --set service.type=ClusterIP --set auth.existingSecret=pgbouncer-auth --set config.adminPassword='supersecret'
kubectl apply -n data -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: pgbouncer-auth
type: Opaque
stringData:
  usernames: keycloak,temporal,temporal_visibility,gitlab,sonarqube,sentry,postgraphile
  passwords: keycloak_pwd,temporal_pwd,temporal_vis_pwd,gitlab_pwd,sonarqube_pwd,sentry_pwd,postgraphile_pwd
EOF
PG_POD=$(kubectl get pod -n data -l app.kubernetes.io/name=postgresql -o jsonpath='{.items[0].metadata.name}')
PG_PASS=$(kubectl get secret postgresql -n data -o jsonpath='{.data.postgres-password}' 2>/dev/null | base64 -d || echo -n 'supersecret')
[ -z "$PG_PASS" ] && PG_PASS='supersecret'
run_psql() {
  kubectl exec -n data "$PG_POD" -c postgresql -- bash -lc \
    "PGPASSWORD='${PG_PASS}' /opt/bitnami/postgresql/bin/psql -U postgres -tAc \"$1\""
}
run_psql "SELECT 1 FROM pg_roles WHERE rolname='keycloak'" || run_psql "CREATE USER keycloak WITH PASSWORD 'keycloak_pwd';"
run_psql "SELECT 1 FROM pg_database WHERE datname='keycloak'" || run_psql "CREATE DATABASE keycloak OWNER keycloak;"
run_psql "SELECT 1 FROM pg_roles WHERE rolname='temporal'" || run_psql "CREATE USER temporal WITH PASSWORD 'temporal_pwd';"
run_psql "SELECT 1 FROM pg_database WHERE datname='temporal'" || run_psql "CREATE DATABASE temporal OWNER temporal;"
run_psql "SELECT 1 FROM pg_roles WHERE rolname='temporal_visibility'" || run_psql "CREATE USER temporal_visibility WITH PASSWORD 'temporal_vis_pwd';"
run_psql "SELECT 1 FROM pg_database WHERE datname='temporal_visibility'" || run_psql "CREATE DATABASE temporal_visibility OWNER temporal_visibility;"
run_psql "SELECT 1 FROM pg_roles WHERE rolname='gitlab'" || run_psql "CREATE USER gitlab WITH PASSWORD 'gitlab_pwd';"
run_psql "SELECT 1 FROM pg_roles WHERE rolname='sonarqube'" || run_psql "CREATE USER sonarqube WITH PASSWORD 'sonarqube_pwd';"
run_psql "SELECT 1 FROM pg_roles WHERE rolname='sentry'" || run_psql "CREATE USER sentry WITH PASSWORD 'sentry_pwd';"
run_psql "SELECT 1 FROM pg_roles WHERE rolname='postgraphile'" || run_psql "CREATE USER postgraphile WITH PASSWORD 'postgraphile_pwd';"

################################################################################

helm upgrade --install keycloak bitnami/keycloak --namespace auth --version 22.2.1 --set postgresql.enabled=false --set externalDatabase.host=postgresql.data.svc.cluster.local --set externalDatabase.user=keycloak --set externalDatabase.password=keycloak_pwd --set externalDatabase.database=keycloak --set auth.adminUser=admin --set auth.adminPassword=change-me --set proxy=edge --set proxyAddressForwarding=true --set ingress.enabled=true --set ingress.hostname=keycloak.aldous.info --set ingress.ingressClassName=kong --set ingress.tls=true --set ingress.extraTls[0].hosts[0]=keycloak.aldous.info --set ingress.extraTls[0].secretName=edge-cert
kubectl apply -f - <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: keycloak
  namespace: auth
spec:
  parentRefs:
  - name: edge
    namespace: gateway
  hostnames:
  - keycloak.aldous.info
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: keycloak
      port: 80
EOF
helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack --namespace observability --version 75.15.0 --set grafana.adminPassword=admin --set grafana.persistence.enabled=true --set grafana.persistence.size=10Gi --set prometheus.prometheusSpec.retention=7d --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.storageClassName=microk8s-hostpath --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=50Gi
cat > /tmp/alertmanager.yaml <<EOF
route:
  group_by: ["job","namespace"]
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  receiver: mailhog
receivers:
- name: mailhog
  email_configs:
  - to: ops@aldous.info
    from: alerts@aldous.info
    smarthost: mailhog.mailhog.svc.cluster.local:1025
    require_tls: false
EOF
helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack --namespace observability --version 75.15.0 -f /tmp/alertmanager.yaml --reuse-values
helm upgrade --install loki grafana/loki \
  --namespace observability \
  --version 6.33.0 \
  -f - <<'EOF'
deploymentMode: SingleBinary
singleBinary:
  replicas: 1
  persistence:
    enabled: true
    size: 50Gi
    storageClass: microk8s-hostpath

loki:
  commonConfig:
    replication_factor: 1
  storage:
    type: filesystem
  schemaConfig:
    configs:
      - from: "2025-01-01"
        store: boltdb-shipper
        object_store: filesystem
        schema: v13
        index:
          prefix: index_
          period: 24h
  storageConfig:
    boltdb_shipper:
      active_index_directory: /var/loki/index
      cache_location: /var/loki/boltdb-cache
      shared_store: filesystem
    filesystem:
      directory: /var/loki/chunks
  ruler:
    storage:
      type: local
      local:
        directory: /var/loki/rules
backend:
  replicas: 0
read:
  replicas: 0
write:
  replicas: 0
gateway:
  enabled: false
EOF
helm upgrade --install promtail grafana/promtail --namespace observability --version 6.16.6 --set config.clients[0].url=http://loki.observability.svc.cluster.local:3100/loki/api/v1/push
helm upgrade --install tempo grafana/tempo \
  --namespace observability --create-namespace \
  --version 1.23.2 \
  -f - <<'EOF'
tempo:
  storage:
    trace:
      backend: local
      wal:
        path: /var/tempo/wal
      local:
        path: /var/tempo/traces
  retention: 168h
persistence:
  enabled: true
  size: 50Gi
  storageClassName: microk8s-hostpath
service:
  type: ClusterIP
gateway:
  enabled: false
EOF
helm upgrade --install opentelemetry-collector opentelemetry/opentelemetry-collector \
  --namespace observability --create-namespace \
  --version 0.97.1 \
  --set image.repository=otel/opentelemetry-collector-k8s \
  --set mode=daemonset \
  -f - <<'EOF'
config:
  receivers:
    otlp:
      protocols:
        http:
        grpc:
    prometheus:
      config:
        scrape_configs:
        - job_name: kubelets
          kubernetes_sd_configs:
          - role: node
  processors:
    batch: {}
  exporters:
    otlphttp/tempo:
      endpoint: http://tempo.observability.svc.cluster.local:4318
      tls:
        insecure: true
    logging:
      loglevel: warn
  service:
    pipelines:
      traces:
        receivers: [otlp]
        processors: [batch]
        exporters: [otlphttp/tempo,logging]
      metrics:
        receivers: [otlp,prometheus]
        processors: [batch]
        exporters: [logging]
      logs:
        receivers: [otlp]
        processors: [batch]
        exporters: [logging]
EOF
helm upgrade --install prometheus-blackbox-exporter prometheus-community/prometheus-blackbox-exporter --namespace observability --version 8.16.0
helm upgrade --install netdata netdata/netdata --namespace observability --version 3.7.89
helm upgrade --install minio bitnami/minio --namespace data --version 14.7.16 --set auth.rootUser=minio --set auth.rootPassword=minio123 --set persistence.enabled=true --set persistence.size=100Gi --set persistence.storageClass=microk8s-hostpath --set defaultBuckets=velero
kubectl apply -n data -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: mc
spec:
  restartPolicy: Never
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - name: mc-home
    emptyDir: {}
  containers:
  - name: mc
    image: bitnami/minio-client:2024
    env:
    - name: HOME
      value: /home/mc
    - name: MC_CONFIG_DIR
      value: /home/mc/.mc
    volumeMounts:
    - name: mc-home
      mountPath: /home/mc
    command: ["/bin/sh","-c"]
    args:
      - mc alias set local http://minio.data.svc.cluster.local:9000 minio minio123 &&
        mc mb -p local/logs-loki || true &&
        mc mb -p local/traces-tempo || true &&
        mc mb -p local/velero || true &&
        mc mb -p local/pg-backups || true &&
        mc mb -p local/gitlab-backups || true &&
        mc mb -p local/opensearch-snapshots || true &&
        mc mb -p local/sentry-backups || true &&
        mc mb -p local/temporal-backups || true &&
        mc mb -p local/artifacts-gitlab || true
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop: ["ALL"]
EOF
kubectl -n data wait --for=condition=Ready pod/mc --timeout=120s || true
kubectl -n data logs mc
kubectl -n data delete pod mc --ignore-not-found

################################################################################

helm upgrade --install redisinsight redisinsight/redisinsight --namespace data --create-namespace --version 0.1.1

helm upgrade --install kafka bitnami/kafka \
  --namespace messaging --create-namespace \
  --version 30.1.5 \
  --set kraft.enabled=false \
  --set zookeeper.enabled=true \
  --set zookeeper.replicaCount=1 \
  --set broker.replicaCount=1 \
  --set controller.replicaCount=0
helm upgrade --install schema-registry bitnami/schema-registry \
  --namespace messaging --create-namespace \
  --version 26.0.1 \
  --set kafka.bootstrapServers=kafka.messaging.svc.cluster.local:9092
helm upgrade --install strimzi-kafka-operator strimzi/strimzi-kafka-operator \
  --namespace messaging --create-namespace \
  --set installCRDs=true
kubectl apply -f https://strimzi.io/install/latest?namespace=messaging
CRD_VERSION=$(kubectl get crd kafkaconnects.kafka.strimzi.io -o jsonpath='{.spec.versions[0].name}')
kubectl apply -n messaging -f - <<EOF
apiVersion: kafka.strimzi.io/${CRD_VERSION}
kind: KafkaConnect
metadata:
  name: my-connect-cluster
spec:
  version: 3.6.0
  replicas: 1
  bootstrapServers: kafka.messaging.svc.cluster.local:9092
  config:
    group.id: connect-cluster
    offset.storage.topic: connect-offsets
    config.storage.topic: connect-configs
    status.storage.topic: connect-status
    config.storage.replication.factor: 1
    offset.storage.replication.factor: 1
    status.storage.replication.factor: 1
EOF

helm upgrade --install akhq akhq/akhq --namespace messaging --version 0.2.0
helm upgrade --install nats nats/nats --namespace messaging --version 1.1.11 --set jetstream.enabled=true
helm upgrade --install opensearch opensearch/opensearch --namespace data --create-namespace --version 3.1.0 --set replicas=1 --set persistence.enabled=true --set persistence.size=100Gi --set persistence.storageClass=microk8s-hostpath --set sysctl.initContainer.enabled=false
helm upgrade --install opensearch-dashboards opensearch/opensearch-dashboards --namespace data --version 3.1.0
helm upgrade --install pgadmin runix/pgadmin4 --namespace data --version 1.24.0 --set env.email=admin@aldous.info --set env.password=admin123
helm upgrade --install mailhog codecentric/mailhog --namespace apps --create-namespace --version 5.8.0
helm upgrade --install temporal temporal/temporal --namespace temporal --version 0.64.0 --set server.config.persistence.default.driver=sql --set server.config.persistence.default.sql.driver=postgres --set server.config.persistence.default.sql.host=postgresql.data.svc.cluster.local --set server.config.persistence.default.sql.port=5432 --set server.config.persistence.default.sql.database=temporal --set server.config.persistence.default.sql.user=temporal --set server.config.persistence.default.sql.password=temporal_pwd --set server.config.persistence.visibility.driver=sql --set server.config.persistence.visibility.sql.driver=postgres --set server.config.persistence.visibility.sql.host=postgresql.data.svc.cluster.local --set server.config.persistence.visibility.sql.port=5432 --set server.config.persistence.visibility.sql.database=temporal_visibility --set server.config.persistence.visibility.sql.user=temporal_visibility --set server.config.persistence.visibility.sql.password=temporal_vis_pwd --set web.enabled=true
kubectl apply -f - <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: temporal-web
  namespace: temporal
spec:
  parentRefs:
    - name: edge
      namespace: gateway
  hostnames:
    - temporal.aldous.info
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /
      backendRefs:
        - name: temporal-web
          port: 8080
EOF

helm upgrade --install sonarqube sonarqube/sonarqube --namespace ci --version 10.6.0 --set persistence.enabled=true --set persistence.size=50Gi --set persistence.storageClass=microk8s-hostpath

kubectl label namespace ci pod-security.kubernetes.io/enforce=baseline --overwrite
kubectl annotate ingressclass kong meta.helm.sh/release-name=gitlab meta.helm.sh/release-namespace=ci --overwrite
helm upgrade --install gitlab gitlab/gitlab \
  --namespace ci \
  --version 7.11.0 \
  --set nginx-ingress.enabled=false \
  --set certmanager.install=false \
  --set global.ingress.configureCertmanager=false \
  --set global.hosts.domain=aldous.info \
  --set global.hosts.externalIP=0.0.0.0 \
  --set global.ingress.class=kong \
  --set global.ingress.tls.secretName=edge-cert \
  --set upgradeCheck.enabled=false \
  --set global.edition=ce \
  --set postgresql.install=true \
  --set postgresql.postgresPassword=supersecret \
  --set postgresql.persistence.enabled=true \
  --set postgresql.persistence.storageClass=microk8s-hostpath \
  --set postgresql.persistence.size=50Gi 

kubectl apply -f - <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: gitlab
  namespace: ci
spec:
  parentRefs:
  - name: edge
    namespace: gateway
  hostnames:
  - gitlab.aldous.info
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: gitlab-webservice-default
      port: 8181
EOF

kubectl apply -n apps -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgraphile
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgraphile
  template:
    metadata:
      labels:
        app: postgraphile
    spec:
      containers:
      - name: postgraphile
        image: graphile/postgraphile:4
        args: ["--connection","postgres://postgraphile:postgraphile_pwd@postgresql.data.svc.cluster.local:5432/postgres","--watch","--enhance-graphiql","--allow-explain"]
        ports:
        - containerPort: 5000
---
apiVersion: v1
kind: Service
metadata:
  name: postgraphile
  namespace: apps
spec:
  selector:
    app: postgraphile
  ports:
  - name: http
    port: 80
    targetPort: 5000
EOF

kubectl apply -f - <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: postgraphile
  namespace: apps
spec:
  parentRefs:
  - name: edge
    namespace: gateway
  hostnames:
  - postgraphile.aldous.info
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: postgraphile
      port: 80
EOF

kubectl apply -n apps -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: presidio-analyzer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: presidio-analyzer
  template:
    metadata:
      labels:
        app: presidio-analyzer
    spec:
      containers:
      - name: analyzer
        image: mcr.microsoft.com/presidio-analyzer:latest
        ports:
        - containerPort: 3000
---
apiVersion: v1
kind: Service
metadata:
  name: presidio-analyzer
  namespace: apps
spec:
  selector:
    app: presidio-analyzer
  ports:
  - port: 80
    targetPort: 3000
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: presidio-anonymizer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: presidio-anonymizer
  template:
    metadata:
      labels:
        app: presidio-anonymizer
    spec:
      containers:
      - name: anonymizer
        image: mcr.microsoft.com/presidio-anonymizer:latest
        ports:
        - containerPort: 3000
---
apiVersion: v1
kind: Service
metadata:
  name: presidio-anonymizer
  namespace: apps
spec:
  selector:
    app: presidio-anonymizer
  ports:
  - port: 80
    targetPort: 3000
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: presidio-redactor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: presidio-redactor
  template:
    metadata:
      labels:
        app: presidio-redactor
    spec:
      containers:
      - name: redactor
        image: mcr.microsoft.com/presidio-image-redactor:latest
        ports:
        - containerPort: 5001
---
apiVersion: v1
kind: Service
metadata:
  name: presidio-redactor
  namespace: apps
spec:
  selector:
    app: presidio-redactor
  ports:
  - port: 80
    targetPort: 5001
EOF

kubectl apply -f - <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: presidio
  namespace: apps
spec:
  parentRefs:
  - name: edge
    namespace: gateway
  hostnames:
  - presidio.aldous.info
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /analyzer
    backendRefs:
    - name: presidio-analyzer
      port: 80
  - matches:
    - path:
        type: PathPrefix
        value: /anonymizer
    backendRefs:
    - name: presidio-anonymizer
      port: 80
  - matches:
    - path:
        type: PathPrefix
        value: /redactor
    backendRefs:
    - name: presidio-redactor
      port: 80
EOF

kubectl apply -n docs -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mkdocs
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mkdocs
  template:
    metadata:
      labels:
        app: mkdocs
    spec:
      containers:
      - name: mkdocs
        image: squidfunk/mkdocs-material
        ports:
        - containerPort: 8000
---
apiVersion: v1
kind: Service
metadata:
  name: mkdocs
  namespace: docs
spec:
  selector:
    app: mkdocs
  ports:
  - port: 80
    targetPort: 8000
EOF

kubectl apply -f - <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: docs
  namespace: docs
spec:
  parentRefs:
  - name: edge
    namespace: gateway
  hostnames:
  - docs.aldous.info
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: mkdocs
      port: 80
EOF

kubectl -n gateway get svc kong-kong-proxy -o wide || true
kubectl get certificate -n gateway edge-cert || true
kubectl get pods --all-namespaces

